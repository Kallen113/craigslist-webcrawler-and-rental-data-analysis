{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function to clean & un-split city names data, from the scraped rental listings CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports-- file processing\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# data analysis libraries & SQL libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# SQL ODBC for API connection between Python & SQL Server\n",
    "import pyodbc\n",
    "import sqlalchemy as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18645 entries, 0 to 18644\n",
      "Data columns (total 48 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   listing_urls             18645 non-null  object \n",
      " 1   ids                      17236 non-null  float64\n",
      " 2   sqft                     13209 non-null  float64\n",
      " 3   cities                   17219 non-null  object \n",
      " 4   prices                   17227 non-null  object \n",
      " 5   bedrooms                 17184 non-null  float64\n",
      " 6   bathrooms                17184 non-null  object \n",
      " 7   attr_vars                17220 non-null  object \n",
      " 8   listing_descrip          17220 non-null  object \n",
      " 9   date_of_webcrawler       17236 non-null  object \n",
      " 10  kitchen                  17220 non-null  float64\n",
      " 11  date_posted              17220 non-null  object \n",
      " 12  region                   18645 non-null  object \n",
      " 13  sub_region               18645 non-null  object \n",
      " 14  cats_OK                  18645 non-null  int64  \n",
      " 15  dogs_OK                  18645 non-null  int64  \n",
      " 16  wheelchair_accessible    18645 non-null  int64  \n",
      " 17  laundry_in_bldg          18645 non-null  int64  \n",
      " 18  no_laundry               18645 non-null  int64  \n",
      " 19  washer_and_dryer         18645 non-null  int64  \n",
      " 20  washer_and_dryer_hookup  18645 non-null  int64  \n",
      " 21  laundry_on_site          18645 non-null  int64  \n",
      " 22  full_kitchen             18645 non-null  int64  \n",
      " 23  dishwasher               18645 non-null  int64  \n",
      " 24  refrigerator             18645 non-null  int64  \n",
      " 25  oven                     18645 non-null  int64  \n",
      " 26  flooring_carpet          18645 non-null  int64  \n",
      " 27  flooring_wood            18645 non-null  int64  \n",
      " 28  flooring_tile            18645 non-null  int64  \n",
      " 29  flooring_hardwood        18645 non-null  int64  \n",
      " 30  flooring_other           18645 non-null  int64  \n",
      " 31  apt_type                 18645 non-null  int64  \n",
      " 32  in_law_apt_type          18645 non-null  int64  \n",
      " 33  condo_type               18645 non-null  int64  \n",
      " 34  townhouse_type           18645 non-null  int64  \n",
      " 35  cottage_or_cabin_type    18645 non-null  int64  \n",
      " 36  single_fam_type          18645 non-null  int64  \n",
      " 37  duplex_type              18645 non-null  int64  \n",
      " 38  is_furnished             18645 non-null  int64  \n",
      " 39  attached_garage          18645 non-null  int64  \n",
      " 40  detached_garage          18645 non-null  int64  \n",
      " 41  carport                  18645 non-null  int64  \n",
      " 42  off_street_parking       18645 non-null  int64  \n",
      " 43  no_parking               18645 non-null  int64  \n",
      " 44  EV_charging              18645 non-null  int64  \n",
      " 45  air_condition            18645 non-null  int64  \n",
      " 46  no_smoking               18645 non-null  int64  \n",
      " 47  Unnamed: 0               535 non-null    float64\n",
      "dtypes: float64(5), int64(33), object(10)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "def recursively_import_all_CSV_and_concat_to_single_df(parent_direc, fn_regex=r'*.csv'):\n",
    "    \"\"\"Recursively search parent directory, and look up all CSV files.\n",
    "    Then, import all CSV files to a single Pandas' df using pd.concat()\"\"\"\n",
    "    path =  parent_direc # specify parent path of directories containing the scraped rental listings CSV data -- NB: use raw text--as in r'path...', or can we use the double-back slashes to escape back-slashes??\n",
    "    df_concat = pd.concat((pd.read_csv(file) for file in glob.iglob(\n",
    "        os.path.join(path, '**', fn_regex), \n",
    "        recursive=True)), ignore_index=True)  # os.path.join helps ensure this concatenation is OS independent\n",
    "    return df_concat\n",
    "\n",
    "## Import Dataset\n",
    "# import all scraped SF bay area rental listings data\n",
    "scraped_data_path = r\"D:\\\\Coding and Code projects\\\\Python\\\\craigslist_data_proj\\\\CraigslistWebScraper\\\\scraped_data\\\\sfbay\"\n",
    "\n",
    "df = recursively_import_all_CSV_and_concat_to_single_df(scraped_data_path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get copy so we can test dataset without having to repeatedly re-load dataset\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding and Code projects\\Python\\craigslist_data_proj\\CraigslistWebScraper\\craigslist_venv\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  app.launch_new_instance()\n",
      "d:\\Coding and Code projects\\Python\\craigslist_data_proj\\CraigslistWebScraper\\craigslist_venv\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Alamo               1\n",
       "Summerville         1\n",
       "San Lorenzo         1\n",
       "Antioch             1\n",
       "Mariner's Island    1\n",
       "Montara             1\n",
       "Windsor             1\n",
       "Portola Valley      1\n",
       "Napa                1\n",
       "Rohnert Park        1\n",
       "Name: cities, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_split_city_names(df, address_critera: list, neighborhood_criteria:list, split_city_delimiters: list):\n",
    "    \"\"\"Clean city names data in several ways:\n",
    "    a.) Remove extraneous address & neighborhood data placed in the city names HTML object, such as 'Rd', 'Blvd', or 'Downtown'.\n",
    "    b.) Unsplit city names data that are split via ',' & '/' delimiters.\n",
    "    c.) Replace abbreviated or mispelled city names.\n",
    "    d.) Remove any digits/integers within the city names data--ie, by using a '\\d+' regex as the argument of str.replace() and replace it with empty strings.\n",
    "    e.) Remove any city names records thast are left with merely empty strings (ie, the other steps removed all data for that given cities record).\n",
    "    f.) Remove any whitespace to avoid the same city names from being treated as different entities by Pandas, Python, or SQL. \n",
    "    g.) Also, use str.capwords() to capitalize words (ie, excluding apostrophes).\"\"\"\n",
    "    addr_criteria = '|'.join(address_critera) # Join pipe ('|') symbols to address list so we can str.split() on any one of these criteria (ie, 'or' condition splitting on each element separated by pipes):\n",
    "    # specify extraneous neighborhood criteria we should also remove from col\n",
    "    nbhood_criteria = '|'.join(neighborhood_criteria) # remove neighborhood names as well as state abbreviation (shown on website as 'Ca') that is shown without the usual comma delimiter!\n",
    "    # b.) specify delimiters we need to refer to un-split city names:\n",
    "    split_city_delimiters = '|'.join(split_city_delimiters) # join pipes to delimiters so we can use str.split() based on multiple 'or' criteria simultaneously\n",
    "    # clean city names data by removing extraneous address & neighborhood data, and unsplitting city names based on ',' & '\\' delimiters\n",
    "    df['cities'] =  df['cities'].str.split(addr_criteria).str[-1].str.replace(nbhood_criteria, '', case=True).str.lstrip()\n",
    "    df['cities'] = df['cities'].str.split(split_city_delimiters).str[0] #unsplit city names based on comma or forward-slash delimiters\n",
    "    # c.) replace specific abbreviated or mispelled city names:\n",
    "    df = df.replace({'cities':{'Rohnert Pk':'Rohnert Park', 'Hillsborough Ca': 'Hillsborough', 'South Sf': 'South San Francisco', \n",
    "    'East San Jose':'San Jose', 'Vallejo Ca':'Vallejo', 'Westgate On Saratoga .':'San Jose', 'Bodega':'Bodega Bay', 'Briarwood At Central Park':'Fremont', 'Campbell Ca': 'Campbell', \n",
    "    'Almaden':'San Jose', '.':'', 'Bend' :'', 'Ketchum':'', 'Baypoinr':'', ' Ca':'', 'Quito': '', \n",
    "    'Lake County''', 'Redding':'', 'Redwood Shores':'Redwood City'}}) \n",
    "    # d.) Remove digits/integers from cities column records:\n",
    "    df['cities'] = df['cities'].str.replace('\\d+', '')  # remove any digits by using '/d+' regex to look up digits, and then replace with empty string\n",
    "    # e.) Remove any rows that have empty strings or null values for cities col (having performed the various data filtering and cleaning above)\n",
    "    df = df[df['cities'].str.strip().astype(bool)] # remove rows with empty strings (ie, '') for cities col \n",
    "    df = df.dropna(subset=['cities']) # remove any remaining 'cities' null records\n",
    "    # f.) Remove whitespace\n",
    "    df['cities'] = df['cities'].str.strip() \n",
    "    # g.) capitalize the city names using str.capwords() \n",
    "    df['cities'] = df['cities'].str.split().apply(lambda x: [val.capitalize() for val in x]).str.join(' ')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# specify various address and street name that we need to remove from the city names \n",
    "address_criteria = ['Boulevard', 'Blvd', 'Road', 'Rd', 'Avenue', 'Ave', 'Street', 'St', ' Dr', 'Drive', 'Real', 'E Hillsdale Blvd'] \n",
    "# specify various extraneous neighborhood names such as 'Downtown' \n",
    "neighborhood_criteria = ['Downtown', 'Central/Downtown', 'North', 'California', 'Ca', 'Ca.', 'Bay Area', 'St. Helena', 'St', 'nyon', 'Jack London Square', 'Walking Distance To', 'El Camino', 'Mendocino County', 'San Mateo County', 'Alameda County', 'Rio Nido Nr', 'Mission Elementary', 'Napa County', 'Golden Gate', 'Jennings', 'South Lake Tahoe', 'Tahoe Paradise', 'Kingswood Estates', 'South Bay', 'Skyline', 'San Antonio Tx', 'East Bay', 'Morton Dr']\n",
    "# specify what delimiters we want to search for to unsplit the split city names data:\n",
    "split_city_delimiters =  [',', '/']\n",
    "\n",
    "# clean city names data:\n",
    "df1 = clean_split_city_names(df1, neighborhood_criteria, address_criteria, split_city_delimiters)\n",
    "# sanity check\n",
    "df1.cities.value_counts().tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "West Marin           26\n",
       "Boulder Creek        26\n",
       "Woodside             26\n",
       "Soquel               20\n",
       "Half Moon Bay        19\n",
       "San Anselmo          18\n",
       "Tiburon              17\n",
       "Hollister            14\n",
       "Larkspur             14\n",
       "Brisbane             13\n",
       "Greenbrae            13\n",
       "Lake County          12\n",
       "Corte Madera         10\n",
       "Occidental            9\n",
       "Redwood Shores        9\n",
       "Saratoga              7\n",
       "Atherton              7\n",
       "Corralitos            6\n",
       "Kentfield             6\n",
       "Forestville           5\n",
       "Westbrae              5\n",
       "Elmwood               5\n",
       "Pinole                4\n",
       "El Sobrante           3\n",
       "Kenwood               3\n",
       "Tracy                 3\n",
       "Kelseyville           3\n",
       "Pleasure Point        2\n",
       "Felton                2\n",
       "Pleasant Hill         2\n",
       "Guerneville           2\n",
       "Bodega Bay            2\n",
       "San Ramon             2\n",
       "Redding               2\n",
       "East Foothills        1\n",
       "Rockridge             1\n",
       "Los Banos             1\n",
       "San Juan Bautista     1\n",
       "Deer Park             1\n",
       "Pleasanton            1\n",
       "Orinda                1\n",
       "San Pablo             1\n",
       "Green Valley          1\n",
       "Bend                  1\n",
       "Rio Vista             1\n",
       "Discovery Bay         1\n",
       "Benicia               1\n",
       "Stro Valley           1\n",
       "Suisun City           1\n",
       "Alamo                 1\n",
       "Summerville           1\n",
       "Antioch               1\n",
       "Mariner's Island      1\n",
       "Montara               1\n",
       "San Lorenzo           1\n",
       "Windsor               1\n",
       "Portola Valley        1\n",
       "Napa                  1\n",
       "Bloomsdale            1\n",
       "Rohnert Park          1\n",
       "Name: cities, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['cities'].value_counts().tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Coding and Code projects\\\\Python\\\\craigslist_data_proj\\\\CraigslistWebScraper\\\\Rentals'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df1.to_csv('cleaned_cities_demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_urls</th>\n",
       "      <th>ids</th>\n",
       "      <th>sqft</th>\n",
       "      <th>cities</th>\n",
       "      <th>prices</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>attr_vars</th>\n",
       "      <th>listing_descrip</th>\n",
       "      <th>date_of_webcrawler</th>\n",
       "      <th>...</th>\n",
       "      <th>is_furnished</th>\n",
       "      <th>attached_garage</th>\n",
       "      <th>detached_garage</th>\n",
       "      <th>carport</th>\n",
       "      <th>off_street_parking</th>\n",
       "      <th>no_parking</th>\n",
       "      <th>EV_charging</th>\n",
       "      <th>air_condition</th>\n",
       "      <th>no_smoking</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9398</th>\n",
       "      <td>https://sfbay.craigslist.org/pen/apa/d/san-car...</td>\n",
       "      <td>7.400148e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Carlos</td>\n",
       "      <td>3,600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>flooring: carpet\\nfurnished\\napartment\\nlaundr...</td>\n",
       "      <td>beautiful corner, spacious, very large 1 bedro...</td>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>https://sfbay.craigslist.org/pen/apa/d/redwood...</td>\n",
       "      <td>7.400148e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Carlos</td>\n",
       "      <td>3,600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>flooring: carpet\\nfurnished\\napartment\\nlaundr...</td>\n",
       "      <td>beautiful corner, spacious, very large 1 bedro...</td>\n",
       "      <td>2021-11-18</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           listing_urls           ids  sqft  \\\n",
       "9398  https://sfbay.craigslist.org/pen/apa/d/san-car...  7.400148e+09   NaN   \n",
       "9909  https://sfbay.craigslist.org/pen/apa/d/redwood...  7.400148e+09   NaN   \n",
       "\n",
       "          cities prices  bedrooms bathrooms  \\\n",
       "9398  San Carlos  3,600       1.0       1.0   \n",
       "9909  San Carlos  3,600       1.0         1   \n",
       "\n",
       "                                              attr_vars  \\\n",
       "9398  flooring: carpet\\nfurnished\\napartment\\nlaundr...   \n",
       "9909  flooring: carpet\\nfurnished\\napartment\\nlaundr...   \n",
       "\n",
       "                                        listing_descrip date_of_webcrawler  \\\n",
       "9398  beautiful corner, spacious, very large 1 bedro...         2021-11-09   \n",
       "9909  beautiful corner, spacious, very large 1 bedro...         2021-11-18   \n",
       "\n",
       "      ...  is_furnished attached_garage detached_garage carport  \\\n",
       "9398  ...             1               1               0       0   \n",
       "9909  ...             1               1               0       0   \n",
       "\n",
       "      off_street_parking  no_parking  EV_charging  air_condition  no_smoking  \\\n",
       "9398                   0           0            0              0           1   \n",
       "9909                   0           0            0              0           1   \n",
       "\n",
       "      Unnamed: 0  \n",
       "9398         NaN  \n",
       "9909         NaN  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['ids'] == 7400147944]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9245c747e8241d920f220897f12edbe786b61c4594b5fa55595ea3a9c3131f03"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 32-bit ('craigslist_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
